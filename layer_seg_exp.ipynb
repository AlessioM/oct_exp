{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from functools import partial\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_conv_scale = 3\n",
    "py_num_blocks = 4\n",
    "py_num_conv_in_block = 2\n",
    "\n",
    "py_input_image_channels = 1\n",
    "py_hidden_channels = 128\n",
    "\n",
    "py_num_classes = 9\n",
    "py_loss_alpha = 1e-4\n",
    "\n",
    "py_learning_rate = 0.01\n",
    "py_decay_rate = 0.95\n",
    "py_decay_step = 30\n",
    "\n",
    "py_momentum = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_helper(y):\n",
    "    \"\"\"Helper to handle indices and logical indices of NaNs.\n",
    "\n",
    "    Input:\n",
    "        - y, 1d numpy array with possible NaNs\n",
    "    Output:\n",
    "        - nans, logical indices of NaNs\n",
    "        - index, a function, with signature indices= index(logical_indices),\n",
    "          to convert logical indices of NaNs to 'equivalent' indices\n",
    "    Example:\n",
    "        >>> # linear interpolation of NaNs\n",
    "        >>> nans, x= nan_helper(y)\n",
    "        >>> y[nans]= np.interp(x(nans), x(~nans), y[~nans])\n",
    "    \"\"\"\n",
    "\n",
    "    return np.isnan(y), lambda z: z.nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_training():\n",
    "    training_case = scipy.io.loadmat(\"data/2015_BOE_Chiu/Subject_%02d.mat\" % (np.random.randint(1,11)))\n",
    "    annotated = [y for y in range(training_case['manualLayers1'].shape[2]) if not np.all(np.isnan(training_case['manualLayers1'][:,:,y]))]\n",
    "    \n",
    "    y = np.random.choice(annotated)\n",
    "\n",
    "    layers = training_case['manualLayers1'][:,:,y].T\n",
    "    layers[layers <= 10] = np.nan\n",
    "    layers[np.isinf(layers)] = np.nan\n",
    "    layers[layers >= 1000] = np.nan\n",
    "    \n",
    "    has_layer_seg = np.where(~np.isnan(np.sum(layers, axis=1)))[0]\n",
    "    x_min, x_max = has_layer_seg[0], has_layer_seg[-1]\n",
    "\n",
    "    layers = training_case['manualLayers1'][:,x_min:x_max,y].T\n",
    "    layers[layers <= 0] = np.nan    \n",
    "    layers[layers >= 1000] = np.nan\n",
    "        \n",
    "    for li in range(layers.shape[1]):\n",
    "        nans, x= nan_helper(layers[:,li])\n",
    "        layers[nans,li] = np.interp(x(nans), x(~nans), layers[~nans,li])\n",
    "    layers = layers.astype(np.int) \n",
    "    \n",
    "    z_min, z_max = np.min(layers), np.max(layers)\n",
    "    z_min -= 20\n",
    "    z_max += 20\n",
    "    layers -= z_min\n",
    "    \n",
    "    \n",
    "    img = training_case['images'][z_min:z_max,x_min:x_max,y]\n",
    "    labels = np.zeros(img.shape + (py_num_classes,))\n",
    "\n",
    "    for x in range(img.shape[1]):\n",
    "        labels[:layers[x,0],x,0] = 1    \n",
    "        labels[layers[x,-1]:,x,py_num_classes-1] = 1    \n",
    "\n",
    "    for i in range(0,py_num_classes-2):\n",
    "        for x in range(img.shape[1]):\n",
    "            labels[layers[x,i]:layers[x,i+1],x,i+1] = 1\n",
    "\n",
    "    return img, labels, layers\n",
    "\n",
    "for e in range(10):\n",
    "    img, labels, layers = get_random_training()\n",
    "    plt.figure(figsize=(20,2))\n",
    "    for i in range(py_num_classes + 1):\n",
    "        plt.subplot(1,py_num_classes + 1,i+1)\n",
    "        if i == 0:\n",
    "            plt.imshow(img[:,:], cmap=plt.cm.gray)\n",
    "            plt.plot(layers[:,:]);\n",
    "        else:            \n",
    "            plt.imshow(labels[:,:,i-1])    \n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_and_dist(tf_data, tf_skip_data_in, block_name):\n",
    "    with tf.variable_scope(block_name):        \n",
    "        for py_conv_in_block in range(py_num_conv_in_block):\n",
    "            with tf.variable_scope(\"conv%d\" % py_conv_in_block):\n",
    "                tf_filter = tf.get_variable(\"filter\",\n",
    "                                            shape=[py_conv_scale, py_conv_scale, py_hidden_channels, py_hidden_channels],\n",
    "                                            initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "\n",
    "                tf_data = tf.nn.conv2d(tf_data,\n",
    "                                       tf_filter,\n",
    "                                       strides=[1,1,1,1],\n",
    "                                       padding=\"SAME\")\n",
    "\n",
    "                if py_conv_in_block == 0:\n",
    "                    tf.summary.histogram(\"%s_direct\" % block_name, tf_filter[:,:,0*py_hidden_channels/4:1*py_hidden_channels/4,:])\n",
    "                    tf.summary.histogram(\"%s_skip\" % block_name,   tf_filter[:,:,1*py_hidden_channels/4:2*py_hidden_channels/4,:])\n",
    "                    tf.summary.histogram(\"%s_up\" % block_name,     tf_filter[:,:,2*py_hidden_channels/4:3*py_hidden_channels/4,:])\n",
    "                    tf.summary.histogram(\"%s_down\" % block_name,   tf_filter[:,:,3*py_hidden_channels/4:4*py_hidden_channels/4,:])                                        \n",
    "                    \n",
    "                tf_data = tf.contrib.layers.batch_norm(tf_data,\n",
    "                                   is_training=True,\n",
    "                                   decay=0.999,\n",
    "                                   center=True,\n",
    "                                   scale=True,\n",
    "                                   activation_fn=tf.nn.relu,\n",
    "                                   updates_collections=None)\n",
    "\n",
    "        with tf.variable_scope(\"bottleneck\"):\n",
    "            tf_filter = tf.get_variable(\"filter\",\n",
    "                                        shape=[py_conv_scale, py_conv_scale, py_hidden_channels, py_hidden_channels/4],\n",
    "                                        initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "\n",
    "            tf_data = tf.nn.conv2d(tf_data,\n",
    "                                   tf_filter,\n",
    "                                   strides=[1,1,1,1],\n",
    "                                   padding=\"SAME\")\n",
    "\n",
    "            tf_data = tf.contrib.layers.batch_norm(tf_data,\n",
    "                               is_training=True,\n",
    "                               decay=0.999,\n",
    "                               center=True,\n",
    "                               scale=True,\n",
    "                               activation_fn=tf.nn.relu,\n",
    "                               updates_collections=None)\n",
    "            tf_skip_data_out = tf_data        \n",
    "\n",
    "        with tf.variable_scope(\"dist\"):\n",
    "            def distance_func(prev_dist, current, alpha):\n",
    "                return tf.maximum(current, \n",
    "                                  tf.subtract(prev_dist, \n",
    "                                              tf.multiply(\n",
    "                                                  tf.subtract(1.0, current), \n",
    "                                                  alpha) ))        \n",
    "\n",
    "            tf_data_sq = tf.squeeze(tf_data, axis=0)\n",
    "\n",
    "            with tf.variable_scope(\"up\"):            \n",
    "                tf_alpha = tf.Variable(1.0, trainable=True, name=\"alpha\")\n",
    "\n",
    "                tf_init = tf.slice(tf_data_sq, [0,0,0], [1,-1,-1])\n",
    "\n",
    "                df = partial(distance_func, alpha=tf_alpha)\n",
    "                tf_data_up = tf.scan(df, tf_data_sq, initializer=tf_init, back_prop=True)\n",
    "                tf_data_up = tf.squeeze(tf_data_up, axis=1)\n",
    "                tf_data_up = tf.expand_dims(tf_data_up, axis=0)\n",
    "\n",
    "            with tf.variable_scope(\"down\"):\n",
    "                tf_alpha = tf.Variable(1.0, trainable=True, name=\"alpha\")\n",
    "\n",
    "                tf_data_reversed = tf.reverse(tf_data_sq, [0])\n",
    "\n",
    "                tf_init = tf.slice(tf_data_reversed, [0,0,0], [1,-1,-1])\n",
    "\n",
    "                df = partial(distance_func, alpha=tf_alpha)\n",
    "                tf_data_down = tf.scan(df, tf_data_reversed, initializer=tf_init, back_prop=True)\n",
    "                tf_data_down = tf.reverse(tf_data_down, [0])\n",
    "                tf_data_down = tf.squeeze(tf_data_down, axis=1)\n",
    "                tf_data_down = tf.expand_dims(tf_data_down, axis=0)\n",
    "\n",
    "        with tf.variable_scope(\"combined\"):\n",
    "            tf_data = tf.concat([tf_skip_data_out, tf_skip_data_in, tf_data_up, tf_data_down], axis=3)        \n",
    "\n",
    "        return tf_data, tf_skip_data_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_graph = tf.Graph()\n",
    "\n",
    "with tf_graph.as_default():\n",
    "    tf_global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "\n",
    "    tf_image  = tf.placeholder(tf.float32, shape=[1, None, None, py_input_image_channels], name=\"input_image\")\n",
    "    tf_labels  = tf.placeholder(tf.int64, shape=[1, None, None, py_num_classes], name=\"input_labels\")\n",
    "    tf_gt_layers  = tf.placeholder(tf.int64, shape=[1, None, py_num_classes - 1], name=\"input_layers\")\n",
    "    \n",
    "    with tf.variable_scope(\"input_conv\"):\n",
    "        tf_filter = tf.get_variable(\"filter\",\n",
    "                                    shape=[py_conv_scale, py_conv_scale, py_input_image_channels, py_hidden_channels * 5 / 4],\n",
    "                                    initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "\n",
    "        tf_data_in = tf.nn.conv2d(tf_image,\n",
    "                               tf_filter,\n",
    "                               strides=[1,1,1,1],\n",
    "                               padding=\"SAME\")\n",
    "\n",
    "        tf_data_in = tf.contrib.layers.batch_norm(tf_data_in,\n",
    "                           is_training=True,\n",
    "                           decay=0.999,\n",
    "                           center=True,\n",
    "                           scale=True,\n",
    "                           activation_fn=tf.nn.relu,\n",
    "                           updates_collections=None)\n",
    "            \n",
    "    tf_skip_data = tf.slice(tf_data_in, [0,0,0,0], [1,-1,-1,py_hidden_channels/4])\n",
    "    tf_data = tf.slice(tf_data_in, [0,0,0,py_hidden_channels/4], [1,-1,-1,py_hidden_channels])\n",
    "    \n",
    "    for j in range(py_num_blocks):\n",
    "        tf_data, tf_skip_data = res_and_dist(tf_data, tf_skip_data, \"block%02d\" % j)    \n",
    "        \n",
    "    with tf.variable_scope(\"output_conv\"):\n",
    "        tf_filter = tf.get_variable(\"filter\",\n",
    "                                    shape=[py_conv_scale, py_conv_scale, py_hidden_channels, py_num_classes],\n",
    "                                    initializer=tf.contrib.layers.xavier_initializer_conv2d())\n",
    "\n",
    "        tf_data = tf.nn.conv2d(tf_data,\n",
    "                               tf_filter,\n",
    "                               strides=[1,1,1,1],\n",
    "                               padding=\"SAME\")\n",
    "\n",
    "        tf_pred = tf.nn.softmax(tf_data)\n",
    "    \n",
    "    with tf.variable_scope(\"layers\"):\n",
    "        py_layers = []\n",
    "        for li in range(py_num_classes -1):\n",
    "            with tf.variable_scope(\"layer%02d\" % li):\n",
    "                \n",
    "                tf_fg_slice = tf.slice(tf_pred, [0,0,0,0], [1,-1,-1,li])\n",
    "                tf_fg_slice = tf.reduce_sum(tf_fg_slice, axis=3)\n",
    "                tf_fg_slice = tf.cumsum(tf_fg_slice, axis=1)\n",
    "                #tf_fg_slice = tf.divide(tf_fg_slice,\n",
    "                #                        tf_fg_slice[0,-1,:],\n",
    "                #                       name=\"foreground\")\n",
    "                \n",
    "                \n",
    "                tf_bg_slice = tf.slice(tf_pred, [0,0,0,li], [1,-1,-1,-1])\n",
    "                tf_bg_slice = tf.reduce_sum(tf_bg_slice, axis=3)\n",
    "                tf_bg_slice = tf.cumsum(tf_bg_slice, axis=1, reverse=True)\n",
    "                #tf_bg_slice = tf.divide(tf_bg_slice,\n",
    "                #                        tf_bg_slice[0,0,:],\n",
    "                #                       name=\"background\")\n",
    "                \n",
    "                tf_layer_pos = tf.argmax(tf_fg_slice + tf_bg_slice, axis=1)                \n",
    "                py_layers.append(tf_layer_pos)\n",
    "                \n",
    "        tf_layers = tf.stack(py_layers, axis=2)\n",
    "\n",
    "    with tf.variable_scope(\"loss\"):\n",
    "        tf_layer_loss = tf.reduce_mean(tf.square(\n",
    "                                            tf.cast(tf_layers, tf.float32) - tf.cast(tf_gt_layers, tf.float32), \n",
    "                                            name=\"layers\")) * py_loss_alpha\n",
    "        \n",
    "        \n",
    "        #tf_layer_loss = tf.reduce_sum(tf.pow(tf.cast(tf_layers-tf_gt_layers, tf.float32), 2)) / (2*tf.cast(tf.shape(tf_gt_layers), tf.float32)[1])\n",
    "        #tf_layer_loss = tf.reduce_mean(tf.nn.log_poisson_loss(tf.cast(tf_gt_layers, tf.float32), tf.cast(tf_layers, tf.float32)))\n",
    "\n",
    "        tf_pixel_loss = tf.losses.softmax_cross_entropy(tf_labels, tf_data)\n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "        #tf_pixel_loss = tf.Print(tf_pixel_loss,  [\"tf_pixel_loss\", tf.shape(tf_pixel_loss), tf_pixel_loss])\n",
    "        #tf_layer_loss = tf.Print(tf_layer_loss,  [\"tf_layer_loss\", tf.shape(tf_layer_loss), tf_layer_loss])\n",
    "        \n",
    "        tf_loss = tf_pixel_loss + tf_layer_loss\n",
    "        #tf_loss = tf.Print(tf_loss,  [\"tf_loss\", tf.shape(tf_loss), tf_loss])\n",
    "        \n",
    "        tf.summary.scalar(\"loss_layer\", tf_layer_loss)\n",
    "        tf.summary.scalar(\"loss_pixel\", tf_pixel_loss)\n",
    "        tf.summary.scalar(\"loss_total\", tf_loss)\n",
    "        \n",
    "        \n",
    "    with tf.variable_scope(\"training\"):\n",
    "        tf_learning_rate = tf.train.exponential_decay(learning_rate=py_learning_rate, \n",
    "                                            global_step=tf_global_step, \n",
    "                                            decay_steps=py_decay_step,  \n",
    "                                            decay_rate=py_decay_rate, \n",
    "                                            staircase=True)\n",
    "        tf.summary.scalar(\"training_learningrate\", tf_learning_rate)\n",
    "        tf_optimizer = tf.train.AdagradOptimizer(learning_rate=tf_learning_rate)\n",
    "        #tf_optimizer = tf.train.GradientDescentOptimizer(learning_rate=tf_learning_rate)\n",
    "        #tf_optimizer = tf.train.MomentumOptimizer(learning_rate=tf_learning_rate, momentum=py_momentum)        \n",
    "        tf_train = tf_optimizer.minimize(tf_loss, global_step=tf_global_step)\n",
    "        \n",
    "    with tf.variable_scope(\"util\"):\n",
    "        tf_init = tf.global_variables_initializer()\n",
    "        tf_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sv = tf.train.Supervisor(logdir=\"first_run_wider\", \n",
    "                         graph=tf_graph,\n",
    "                         init_op=tf_init,\n",
    "                         summary_op=None)\n",
    "\n",
    "\n",
    "\n",
    "with sv.managed_session() as sess:        \n",
    "#with tf.Session(graph=tf_graph) as sess:        \n",
    "    sess.run([tf_init])\n",
    "    for e in range(5000):\n",
    "        img, labels, layers = get_random_training()\n",
    "        if sv.should_stop():\n",
    "            break        \n",
    "        for i in range(10):\n",
    "            if sv.should_stop():\n",
    "                break\n",
    "            py_feed_dict = {tf_image: img[np.newaxis,:,:,np.newaxis],\n",
    "                            tf_labels: labels[np.newaxis,:,:,:],\n",
    "                            tf_gt_layers: layers[np.newaxis,:,:]}\n",
    "            (py_summary, py_loss,_, py_pred, py_layers) = sess. run([\n",
    "                tf_summary, tf_loss, tf_train, tf_pred, tf_layers], \n",
    "                                             feed_dict=py_feed_dict)    \n",
    "            sv.summary_computed(sess, py_summary)\n",
    "            print  py_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))        \n",
    "for i in range(py_num_classes):\n",
    "    \n",
    "    plt.subplot(py_num_classes,2,i*2+1)\n",
    "    plt.imshow(py_pred[0,:,:,i])    \n",
    "    plt.plot(py_layers[0,:,:]);\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(py_num_classes,2,i*2+2)\n",
    "    plt.imshow(labels[:,:,i])  \n",
    "    plt.plot(layers[:,:]);\n",
    "    plt.axis('off')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
